# âš¡SHAURYA v.0.2.0 - Scalable High-Frequency Architecture for Ultra-low Response Yield Access

![Language](https://img.shields.io/badge/language-C%2B%2B17-blue.svg)
![Latency](https://img.shields.io/badge/min%20latency-300%20ns-brightgreen.svg)
![Architecture](https://img.shields.io/badge/architecture-Lock--Free-orange.svg)
![Parsing](https://img.shields.io/badge/parsing-Zero--Copy-red.svg)
![Compiler](https://img.shields.io/badge/compiler-LLVM%2FClang-purple.svg)
![AI](https://img.shields.io/badge/AI-Zero%20Dependency%20Inference-teal.svg)
![Risk](https://img.shields.io/badge/risk-FPGA--Style%20Firewall-critical.svg)
![Pipeline](https://img.shields.io/badge/pipeline-88Âµs%20End--to--End-success.svg)
![Training](https://img.shields.io/badge/Training-Python-yellow.svg)
![Fusion](https://img.shields.io/badge/Compiler-LLVM%20Fusion-purple.svg)
![Execution](https://img.shields.io/badge/Execution-Vectorized%20CPU-brightgreen.svg)
![Inference](https://img.shields.io/badge/Inference-Eigen%20AI-orange.svg)
![Risk](https://img.shields.io/badge/Risk-FPGA%20Firewall-critical.svg)
![Networking](https://img.shields.io/badge/Networking-Lock--Free-red.svg)
---

## ğŸ§  Introduction

**Shaurya (`hft.shaurya`)** is an ultra-low latency heterogeneous high-frequency trading (HFT) framework that bridges Python-based AI model development with deterministic C++ execution performance.

Designed for:

- ğŸ“ˆ Quantitative Researchers  
- ğŸ¢ Proprietary Trading Engineers  
- âš™ï¸ Systems Programmers  
- ğŸ“ HPC & Compiler Enthusiasts  

Shaurya enables **deep learning inference, hardware-style risk control, and lock-free networking** in a unified deterministic execution pipeline.

> âš¡ Full pipeline latency: ~88Âµs  
> (Network â†’ FIX Parse â†’ AI Inference â†’ FPGA Risk â†’ Routing)

---

## ğŸ“‘ Table of Contents

- [Architecture Overview](#-architecture-overview)
- [Key Features](#-key-features)
- [Installation](#-installation)
- [Usage Guide](#usage-guide)
- [Technical Deep Dive](#-technical-deep-dive)
- [Performance Metrics](#-performance-metrics)
- [Configuration](#-configuration)
- [Examples](#-examples)
- [Troubleshooting](#-troubleshooting)
- [Roadmap](#-roadmap)

---

# ğŸ§± Architecture Overview

Python Training â†’ Model Export â†’ LLVM Fusion â†’ Vectorized CPU Execution
â”‚
â”œâ”€â”€ Eigen AI Inference
â”œâ”€â”€ FPGA Risk Firewall
â””â”€â”€ Lock-Free Networking


Shaurya follows a **Heterogeneous Software-in-the-Loop (SIL)** architecture:

| Layer | Purpose |
|-------|----------|
| ğŸ Python | Train ML models (TensorFlow/Keras) |
| âš™ï¸ C++ | Deterministic inference execution |
| ğŸ”Œ RTL-style Risk | Hardware-like safety validation |
| ğŸ”§ LLVM/Clang | Whole-program optimization + LTO fusion |

---

# ğŸš€ Key Features

## âœ… Deterministic AI Inference
- No Python runtime
- No GIL
- No garbage collection pauses
- Header-only inference
- Eigen-backed linear algebra

## âœ… FPGA-Style Risk Firewall
- Fat-finger protection
- Kill-switch logic
- Rate limiting
- Price-range validation
- Branchless logic design

## âœ… Lock-Free Networking
- SPSC ring buffer
- `std::atomic` synchronization
- Cache-line aligned memory (`alignas(64)`)
- Zero-copy FIX handling

## âœ… LLVM Fusion
- `-flto` Link-Time Optimization
- Cross-module inlining
- Dead code elimination
- `-march=native` AVX2 vectorization
- `-ffast-math` throughput optimization

---

# ğŸ“¦ Installation

### ğŸ›£ï¸ Python Gateway

```bash
pip install hft.shaurya==0.2.0
```

`C++ Core Requires:`

1. LLVM/Clang
2. `lld linker`
3. C++17 compatible compiler

> Build using provided scripts:
```
clang++ -O3 -flto -march=native -ffast-math ...
```
`Then run:`
```
bin\Shaurya.exe
```
---

# ğŸ”¨Usage Guide

##  ğŸ• Step 1: Start Market Gateway
```
python -m hft.shaurya.gateway
```
or
```
python bridge.py
```
> The Python layer:

1. Aggregates exchange feeds

2. Streams FIX messages locally

3. Forwards data to C++ core

## ğŸ•‘ Step 2: Launch LLVM C++ Core

```
bin\Shaurya.exe
```
> Startup Process:

1. Loads AI weights
2. Warms CPU instruction cache
3. Initializes ring buffers
4. Begins live tick processing

## ğŸ•’ Step 3 â€” Review Metrics

> After shutdown (Ctrl + C)
ğŸŒ  Shaurya_Metrics.txt includes:

1. Average latency
2. 99th percentile
3. Tail latency distribution
4. Message throughput

---

# ğŸ”¬ Technical Deep Dive

## 1ï¸âƒ£ LLVM/Clang Infrastructure

> Shaurya prioritizes LLVM over GCC for:

- Whole-program analysis
- Cross-module inlining
- Vectorized math fusion
- Aggressive dead-code elimination

- Compiler flags used:
```
-flto
-march=native
-ffast-math
```

## 2ï¸âƒ£ Deep Learning Alpha Engine

> Model Pipeline
```
.h5 (Keras)
   â†“
fdeep_model.json
   â†“
Header-only C++ inference
```

`Benefits:`

1. No Python interpreter
2. No runtime framework
3. Cache-friendly execution
4. Deterministic latency


## 3ï¸âƒ£ Software-in-the-Loop FPGA Risk Engine

 ```
Traditional systems:

if(price > limit) { block(); }
```

## ğŸ—ºï¸ Shaurya approach:

1. Gate-style evaluation
2. Branchless evaluation trees
3. Avoids branch predictor penalties
4. Emulates RTL-style hardware logic

`Sample output:`
```
[FPGA: BLOCKED (FAT FINGER)]
```

## 4ï¸âƒ£ Zero-Copy Lock-Free Pipeline

1. Single-producer single-consumer (SPSC)
2. Atomic pointer arithmetic
3. Cache-aligned buffers
4. No mutex locks
5. No scheduler interference

---

# ğŸ“Š Performance Metrics

## ğŸ’ªğŸ» Benchmark Method

- Windows `QueryPerformanceCounter`
- Full tick lifecycle measurement:
  - Network Buffer  
  - FIX Parse  
  - AI Inference  
  - FPGA Risk Gate  
  - Routing  

## âœ… Results

| Metric              | Value     |
|---------------------|----------|
| Messages Tested     | 1000+    |
| Minimum Latency     | 3.6 Âµs   |
| Average Latency     | 88.38 Âµs |
| 99th Percentile     | 237.0 Âµs |

> 99% of trades complete in under **0.25 milliseconds**, even under OS scheduler load.

---

# ğŸ”© Configuration 

> Key Optimization Flags

```bash
-O3
-flto
-march=native
-ffast-math
```

ğŸ Recommended System Tuning

- Disable power-saving modes  
- Pin threads to dedicated CPU cores  
- Use performance CPU governor (Linux)  
- Disable unnecessary background processes  

---

# ğŸ’¡ Examples

> Running a Trained Model

1. Train model in Python  
2. Export `.h5`  
3. Convert to `fdeep_model.json`  
4. Place model in inference directory  
5. Launch core engine  

---

> Risk Rule Example

```cpp
RiskGate fatFinger( max_notional = 1'000'000 );
RiskGate priceClamp( max_slippage = 0.5% );
```

---


# ğŸ¯ Who Benefits?

## ğŸ“ˆ Retail & Quant Traders

- AI-driven live execution  
- Sub-millisecond architecture  
- Institutional-grade safety  

## ğŸ¢ Proprietary Firms

- Rapid FPGA prototyping (SIL)  
- Deterministic backtesting  
- Infrastructure experimentation  

## ğŸ“ Computer Science Students

Real-world examples of:

- Lock-free systems  
- LLVM optimization  
- Vectorized math  
- HPC finance pipelines  

---

# ğŸš€ Roadmap

- [ ] GPU kernel fusion experiments  
- [ ] Native FPGA backend  
- [ ] Linux ultra-low-latency build  
- [ ] Advanced order routing simulator  
- [ ] Real exchange connectivity modules  

---

# ğŸ§ª Troubleshooting

## ğŸ“ˆ High Latency Spikes

- Verify CPU scaling disabled  
- Ensure LTO enabled  
- Confirm AVX2 available  

## ğŸ™…ğŸ»â€â™€ï¸ Model Not Loading

- Validate `fdeep_model.json`  
- Ensure correct path  
- Check weight precision compatibility  

## ğŸ¢ Build Issues

- Confirm Clang version compatibility  
- Ensure `lld` installed  
- Rebuild with verbose logging  

---

# â˜¢ï¸ Disclaimer

> Shaurya is intended for:

- Research  
- Education  
- Systems experimentation  

`It is not financial advice and not production-certified trading infrastructure.`

> Users assume full responsibility for:

- Trading decisions  
- Compliance  
- Regulatory adherence  
- Capital risk  

---

# ğŸ Final Note

The engine is solely contributed by Harshit Kumar Singh, me(;

Shaurya v.0.2.0 represents a shift toward democratized institutional-grade infrastructure : merging AI, compiler engineering, and hardware-style safety into a single deterministic execution engine.
>If this project helps you, consider â­ starring the repository and contributing to future releases and till then happy coding ğŸ˜Š.

`ad astra per aspera ğŸ›©ï¸`
